{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/michelangelo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/michelangelo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/michelangelo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database - change path accordingly\n",
    "engine = create_engine('sqlite:///../data/data_db/DisasterReponses.db')\n",
    "df = pd.read_sql(\"SELECT * FROM DisasterReponses\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0        0      0            0             0                 0  ...   \n",
       "1        0      0            1             0                 0  ...   \n",
       "2        0      0            0             0                 0  ...   \n",
       "3        1      0            1             0                 1  ...   \n",
       "4        0      0            0             0                 0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The messages will be the features, while the categories will be the target variables\n",
    "X = df.message.to_numpy() \n",
    "y = df[df.columns[4:]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete feature dataset size =  (26216,) ; complete target variables size =  (26216, 36)\n"
     ]
    }
   ],
   "source": [
    "# Check size of dataset\n",
    "print(\"Complete feature dataset size = \", X.shape, \"; complete target variables size = \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Weather update - a cold front from Cuba that could pass over Haiti',\n",
       " array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what's in X, y\n",
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['related',\n",
       " 'request',\n",
       " 'offer',\n",
       " 'aid_related',\n",
       " 'medical_help',\n",
       " 'medical_products',\n",
       " 'search_and_rescue',\n",
       " 'security',\n",
       " 'military',\n",
       " 'child_alone',\n",
       " 'water',\n",
       " 'food',\n",
       " 'shelter',\n",
       " 'clothing',\n",
       " 'money',\n",
       " 'missing_people',\n",
       " 'refugees',\n",
       " 'death',\n",
       " 'other_aid',\n",
       " 'infrastructure_related',\n",
       " 'transport',\n",
       " 'buildings',\n",
       " 'electricity',\n",
       " 'tools',\n",
       " 'hospitals',\n",
       " 'shops',\n",
       " 'aid_centers',\n",
       " 'other_infrastructure',\n",
       " 'weather_related',\n",
       " 'floods',\n",
       " 'storm',\n",
       " 'fire',\n",
       " 'earthquake',\n",
       " 'cold',\n",
       " 'other_weather',\n",
       " 'direct_report']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, save the names of the category labels\n",
    "category_names = list(df.columns[4:])\n",
    "category_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # normalize case and remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # tokenize text\n",
    "    tokens_raw = word_tokenize(text)\n",
    "    \n",
    "    # lemmatize and remove stop words\n",
    "    tokens = [WordNetLemmatizer().lemmatize(word) for word in tokens_raw if (word not in stopwords.words('english'))]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather update - a cold front from Cuba that could pass over Haiti\n",
      "['weather', 'update', 'cold', 'front', 'cuba', 'could', 'pas', 'haiti'] \n",
      "\n",
      "Is the Hurricane over or is it not over\n",
      "['hurricane'] \n",
      "\n",
      "Looking for someone but no name\n",
      "['looking', 'someone', 'name'] \n",
      "\n",
      "UN reports Leogane 80-90 destroyed. Only Hospital St. Croix functioning. Needs supplies desperately.\n",
      "['un', 'report', 'leogane', '80', '90', 'destroyed', 'hospital', 'st', 'croix', 'functioning', 'need', 'supply', 'desperately'] \n",
      "\n",
      "says: west side of Haiti, rest of the country today and tonight\n",
      "['say', 'west', 'side', 'haiti', 'rest', 'country', 'today', 'tonight'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test function for the first 5 messages\n",
    "for message in X[:5]:\n",
    "    tokens = tokenize(message)\n",
    "    print(message)\n",
    "    print(tokens, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split data in test/train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training feature dataset size =  (19662,) ; training target variables size =  (19662, 36)\n",
      "Testing feature dataset size =  (6554,) ; testing target variables size =  (6554, 36)\n"
     ]
    }
   ],
   "source": [
    "# Check size of datasets - default split is 75% train / 25% test\n",
    "print(\"Training feature dataset size = \", X_train.shape, \"; training target variables size = \", y_train.shape)\n",
    "print(\"Testing feature dataset size = \", X_test.shape, \"; testing target variables size = \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier())),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.a. Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier, keeping track of time\n",
    "t0= time.clock()\n",
    "\n",
    "pipeline.fit(X_train, y_train);\n",
    "\n",
    "t1 = time.clock() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('elapsed time = ', t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.b. Load saved pipeline\n",
    "\n",
    "In case the pipeline was saved previously you can load it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionary \n",
    "filename = '../models/models_files/random_forest_pipeline_1.pickle'\n",
    "pipeline_dict = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get content\n",
    "X_train = pipeline_dict['X_train']\n",
    "y_train = pipeline_dict['y_train']\n",
    "X_test = pipeline_dict['X_test']\n",
    "y_test = pipeline_dict['y_test']\n",
    "pipeline = pipeline_dict['pipeline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Test your pipeline\n",
    " - Predict outcomes based on test data\n",
    " - Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.43      0.53      1529\n",
      "           1       0.84      0.94      0.89      4977\n",
      "           2       0.35      0.35      0.35        48\n",
      "\n",
      "    accuracy                           0.82      6554\n",
      "   macro avg       0.63      0.58      0.59      6554\n",
      "weighted avg       0.80      0.82      0.80      6554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display example of results \n",
    "print(classification_report(y_test[:,0], y_pred[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "Label =  related\n",
      "Value =  0 : precision =  0.70 ; recall =  0.43 ; f1-s = 0.53 ; support = 1529\n",
      "Value =  1 : precision =  0.84 ; recall =  0.94 ; f1-s = 0.89 ; support = 4977\n",
      "Value =  2 : precision =  0.35 ; recall =  0.35 ; f1-s = 0.35 ; support = 48\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  request\n",
      "Value =  0 : precision =  0.90 ; recall =  0.98 ; f1-s = 0.94 ; support = 5433\n",
      "Value =  1 : precision =  0.82 ; recall =  0.48 ; f1-s = 0.60 ; support = 1121\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  offer\n",
      "Value =  0 : precision =  1.00 ; recall =  1.00 ; f1-s = 1.00 ; support = 6526\n",
      "Value =  1 : precision =  0.00 ; recall =  0.00 ; f1-s = 0.00 ; support = 28\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  aid_related\n",
      "Value =  0 : precision =  0.80 ; recall =  0.84 ; f1-s = 0.82 ; support = 3881\n",
      "Value =  1 : precision =  0.75 ; recall =  0.70 ; f1-s = 0.72 ; support = 2673\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  medical_help\n",
      "Value =  0 : precision =  0.93 ; recall =  1.00 ; f1-s = 0.96 ; support = 6042\n",
      "Value =  1 : precision =  0.60 ; recall =  0.08 ; f1-s = 0.14 ; support = 512\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  medical_products\n",
      "Value =  0 : precision =  0.95 ; recall =  1.00 ; f1-s = 0.97 ; support = 6215\n",
      "Value =  1 : precision =  0.74 ; recall =  0.08 ; f1-s = 0.15 ; support = 339\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  search_and_rescue\n",
      "Value =  0 : precision =  0.97 ; recall =  1.00 ; f1-s = 0.99 ; support = 6360\n",
      "Value =  1 : precision =  0.78 ; recall =  0.07 ; f1-s = 0.13 ; support = 194\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  security\n",
      "Value =  0 : precision =  0.98 ; recall =  1.00 ; f1-s = 0.99 ; support = 6436\n",
      "Value =  1 : precision =  0.00 ; recall =  0.00 ; f1-s = 0.00 ; support = 118\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  military\n",
      "Value =  0 : precision =  0.97 ; recall =  1.00 ; f1-s = 0.98 ; support = 6343\n",
      "Value =  1 : precision =  0.81 ; recall =  0.06 ; f1-s = 0.11 ; support = 211\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  child_alone\n",
      "Value =  0 : precision =  1.00 ; recall =  1.00 ; f1-s = 1.00 ; support = 6554\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  water\n",
      "Value =  0 : precision =  0.95 ; recall =  1.00 ; f1-s = 0.97 ; support = 6129\n",
      "Value =  1 : precision =  0.90 ; recall =  0.28 ; f1-s = 0.43 ; support = 425\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  food\n",
      "Value =  0 : precision =  0.95 ; recall =  0.98 ; f1-s = 0.97 ; support = 5840\n",
      "Value =  1 : precision =  0.81 ; recall =  0.61 ; f1-s = 0.69 ; support = 714\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  shelter\n",
      "Value =  0 : precision =  0.95 ; recall =  0.99 ; f1-s = 0.97 ; support = 5985\n",
      "Value =  1 : precision =  0.80 ; recall =  0.40 ; f1-s = 0.54 ; support = 569\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  clothing\n",
      "Value =  0 : precision =  0.99 ; recall =  1.00 ; f1-s = 0.99 ; support = 6448\n",
      "Value =  1 : precision =  0.63 ; recall =  0.11 ; f1-s = 0.19 ; support = 106\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  money\n",
      "Value =  0 : precision =  0.98 ; recall =  1.00 ; f1-s = 0.99 ; support = 6402\n",
      "Value =  1 : precision =  0.50 ; recall =  0.01 ; f1-s = 0.03 ; support = 152\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  missing_people\n",
      "Value =  0 : precision =  0.99 ; recall =  1.00 ; f1-s = 0.99 ; support = 6480\n",
      "Value =  1 : precision =  1.00 ; recall =  0.01 ; f1-s = 0.03 ; support = 74\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  refugees\n",
      "Value =  0 : precision =  0.97 ; recall =  1.00 ; f1-s = 0.98 ; support = 6322\n",
      "Value =  1 : precision =  0.59 ; recall =  0.04 ; f1-s = 0.08 ; support = 232\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  death\n",
      "Value =  0 : precision =  0.96 ; recall =  1.00 ; f1-s = 0.98 ; support = 6252\n",
      "Value =  1 : precision =  0.77 ; recall =  0.15 ; f1-s = 0.25 ; support = 302\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  other_aid\n",
      "Value =  0 : precision =  0.87 ; recall =  1.00 ; f1-s = 0.93 ; support = 5693\n",
      "Value =  1 : precision =  0.67 ; recall =  0.04 ; f1-s = 0.07 ; support = 861\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  infrastructure_related\n",
      "Value =  0 : precision =  0.94 ; recall =  1.00 ; f1-s = 0.97 ; support = 6132\n",
      "Value =  1 : precision =  0.29 ; recall =  0.00 ; f1-s = 0.01 ; support = 422\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  transport\n",
      "Value =  0 : precision =  0.96 ; recall =  1.00 ; f1-s = 0.98 ; support = 6255\n",
      "Value =  1 : precision =  0.69 ; recall =  0.07 ; f1-s = 0.12 ; support = 299\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  buildings\n",
      "Value =  0 : precision =  0.96 ; recall =  1.00 ; f1-s = 0.98 ; support = 6245\n",
      "Value =  1 : precision =  0.73 ; recall =  0.12 ; f1-s = 0.21 ; support = 309\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  electricity\n",
      "Value =  0 : precision =  0.98 ; recall =  1.00 ; f1-s = 0.99 ; support = 6407\n",
      "Value =  1 : precision =  0.83 ; recall =  0.03 ; f1-s = 0.07 ; support = 147\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  tools\n",
      "Value =  0 : precision =  0.99 ; recall =  1.00 ; f1-s = 1.00 ; support = 6502\n",
      "Value =  1 : precision =  0.00 ; recall =  0.00 ; f1-s = 0.00 ; support = 52\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  hospitals\n",
      "Value =  0 : precision =  0.99 ; recall =  1.00 ; f1-s = 0.99 ; support = 6477\n",
      "Value =  1 : precision =  0.00 ; recall =  0.00 ; f1-s = 0.00 ; support = 77\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  shops\n",
      "Value =  0 : precision =  0.99 ; recall =  1.00 ; f1-s = 1.00 ; support = 6515\n",
      "Value =  1 : precision =  0.00 ; recall =  0.00 ; f1-s = 0.00 ; support = 39\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  aid_centers\n",
      "Value =  0 : precision =  0.99 ; recall =  1.00 ; f1-s = 0.99 ; support = 6488\n",
      "Value =  1 : precision =  0.00 ; recall =  0.00 ; f1-s = 0.00 ; support = 66\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  other_infrastructure\n",
      "Value =  0 : precision =  0.96 ; recall =  1.00 ; f1-s = 0.98 ; support = 6271\n",
      "Value =  1 : precision =  0.50 ; recall =  0.01 ; f1-s = 0.02 ; support = 283\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  weather_related\n",
      "Value =  0 : precision =  0.89 ; recall =  0.95 ; f1-s = 0.92 ; support = 4719\n",
      "Value =  1 : precision =  0.85 ; recall =  0.68 ; f1-s = 0.76 ; support = 1835\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  floods\n",
      "Value =  0 : precision =  0.95 ; recall =  1.00 ; f1-s = 0.97 ; support = 5997\n",
      "Value =  1 : precision =  0.90 ; recall =  0.46 ; f1-s = 0.61 ; support = 557\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  storm\n",
      "Value =  0 : precision =  0.95 ; recall =  0.98 ; f1-s = 0.97 ; support = 5945\n",
      "Value =  1 : precision =  0.78 ; recall =  0.53 ; f1-s = 0.63 ; support = 609\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  fire\n",
      "Value =  0 : precision =  0.99 ; recall =  1.00 ; f1-s = 0.99 ; support = 6473\n",
      "Value =  1 : precision =  0.00 ; recall =  0.00 ; f1-s = 0.00 ; support = 81\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  earthquake\n",
      "Value =  0 : precision =  0.98 ; recall =  0.99 ; f1-s = 0.98 ; support = 5949\n",
      "Value =  1 : precision =  0.89 ; recall =  0.77 ; f1-s = 0.83 ; support = 605\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  cold\n",
      "Value =  0 : precision =  0.98 ; recall =  1.00 ; f1-s = 0.99 ; support = 6419\n",
      "Value =  1 : precision =  0.79 ; recall =  0.08 ; f1-s = 0.15 ; support = 135\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  other_weather\n",
      "Value =  0 : precision =  0.95 ; recall =  1.00 ; f1-s = 0.97 ; support = 6189\n",
      "Value =  1 : precision =  0.64 ; recall =  0.04 ; f1-s = 0.07 ; support = 365\n",
      "-----------------------------------------------------------------------------------------\n",
      "Label =  direct_report\n",
      "Value =  0 : precision =  0.87 ; recall =  0.97 ; f1-s = 0.92 ; support = 5313\n",
      "Value =  1 : precision =  0.76 ; recall =  0.36 ; f1-s = 0.48 ; support = 1241\n"
     ]
    }
   ],
   "source": [
    "# Iterate and print on screen and file\n",
    "for ind_1 in range(y_pred.shape[1]):\n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    print('Label = ', category_names[ind_1])\n",
    "    c_rep = classification_report(y_test[:,ind_1], y_pred[:,ind_1], output_dict=True, zero_division=0)\n",
    "    kk = list(c_rep.keys())\n",
    "    for ind_2 in range(len(c_rep) - 3):\n",
    "        print('Value = ', kk[ind_2], ': precision = ', \"{:.2f}\".format(c_rep[kk[ind_2]]['precision']),\n",
    "              '; recall = ', \"{:.2f}\".format(c_rep[kk[ind_2]]['recall']), \n",
    "              '; f1-s =', \"{:.2f}\".format(c_rep[kk[ind_2]]['f1-score']),\n",
    "              '; support =', c_rep[kk[ind_2]]['support'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the following cells if you want to save the previous report on a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this (or add the library in the import section) if you want to save results in a text file including \n",
    "# the date of the test\n",
    "# from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change this accordingly to your wish\n",
    "output_file_path = '../models/models_files/'\n",
    "# You can pick the format for the score file name\n",
    "# output_file_name = 'score_results_' + datetime.now().strftime('%Y_%m_%d') + '.txt' \n",
    "output_file_name = 'score_results_random_forest_pipeline_1.txt'\n",
    "output_file_full_name = output_file_path + output_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate and print on file\n",
    "with open(output_file_full_name, \"w\") as text_file:\n",
    "    for ind_1 in range(y_pred.shape[1]):\n",
    "        print('-----------------------------------------------------------------------------------------', file=text_file)\n",
    "        print('Label = ', category_names[ind_1], file=text_file)\n",
    "        c_rep = classification_report(y_test[:,ind_1], y_pred[:,ind_1], output_dict=True, zero_division=0)\n",
    "        kk = list(c_rep.keys())\n",
    "        for ind_2 in range(len(c_rep) - 3):\n",
    "            print('Value = ', kk[ind_2], ': precision = ', \"{:.2f}\".format(c_rep[kk[ind_2]]['precision']),\n",
    "                '; recall = ', \"{:.2f}\".format(c_rep[kk[ind_2]]['recall']),\n",
    "                '; f1-s =', \"{:.2f}\".format(c_rep[kk[ind_2]]['f1-score']),\n",
    "                '; support =', c_rep[kk[ind_2]]['support'], file=text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have just now created the pipeline, save it and the data in a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for pickle file\n",
    "pipeline_dict_2 = {'X_train':X_train,\n",
    "                    'y_train':y_train,\n",
    "                    'X_test':X_test,\n",
    "                    'y_test':y_test,\n",
    "                    'pipeline':pipeline}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionary\n",
    "filename = '../models/models_files/random_forest_pipeline_1.pickle'\n",
    "pickle.dump(classifier_dict_2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(tokenizer=<function tokenize at 0x7ff9aaec0510>)),\n",
       "  ('tfidf', TfidfTransformer()),\n",
       "  ('clf', MultiOutputClassifier(estimator=RandomForestClassifier()))],\n",
       " 'verbose': False,\n",
       " 'vect': CountVectorizer(tokenizer=<function tokenize at 0x7ff9aaec0510>),\n",
       " 'tfidf': TfidfTransformer(),\n",
       " 'clf': MultiOutputClassifier(estimator=RandomForestClassifier()),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__estimator__bootstrap': True,\n",
       " 'clf__estimator__ccp_alpha': 0.0,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': 'auto',\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__max_samples': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_impurity_split': None,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__n_estimators': 100,\n",
       " 'clf__estimator__n_jobs': None,\n",
       " 'clf__estimator__oob_score': False,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__verbose': 0,\n",
       " 'clf__estimator__warm_start': False,\n",
       " 'clf__estimator': RandomForestClassifier(),\n",
       " 'clf__n_jobs': None}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find what are the parameters of the pipeline\n",
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid search parameters\n",
    "parameters = {\n",
    "#         'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "        'vect__max_df': (0.5, 0.75, 1.0),\n",
    "#         'vect__max_features': (None, 5000, 10000),\n",
    "#         'tfidf__use_idf': (True, False),\n",
    "#         'clf__estimator__n_estimators': [50, 100, 200],\n",
    "#         'clf__estimator__min_samples_split': [2, 3, 4]\n",
    "    }\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Running the grid search on the full parameter space can take a **_lot_** of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier, keeping track of time\n",
    "t0= time.clock()\n",
    "\n",
    "cv.fit(X_train, y_train);\n",
    "\n",
    "t1 = time.clock() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
